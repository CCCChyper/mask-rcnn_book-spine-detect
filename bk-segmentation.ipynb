{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01f716af",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-25T14:59:46.958783Z",
     "iopub.status.busy": "2024-08-25T14:59:46.958410Z",
     "iopub.status.idle": "2024-08-25T14:59:47.691285Z",
     "shell.execute_reply": "2024-08-25T14:59:47.690325Z"
    },
    "papermill": {
     "duration": 0.74077,
     "end_time": "2024-08-25T14:59:47.693756",
     "exception": false,
     "start_time": "2024-08-25T14:59:46.952986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09b0e763",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T14:59:47.702791Z",
     "iopub.status.busy": "2024-08-25T14:59:47.701965Z",
     "iopub.status.idle": "2024-08-25T14:59:47.707407Z",
     "shell.execute_reply": "2024-08-25T14:59:47.706599Z"
    },
    "papermill": {
     "duration": 0.012151,
     "end_time": "2024-08-25T14:59:47.709760",
     "exception": false,
     "start_time": "2024-08-25T14:59:47.697609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Adding cite path is done\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "if('/kaggle/input/references') not in sys.path:\n",
    "    print(sys.path.append('/kaggle/input/references'))\n",
    "    print('Adding cite path is done')\n",
    "else:\n",
    "    print('Cite path added')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f1d0eb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T14:59:47.718746Z",
     "iopub.status.busy": "2024-08-25T14:59:47.718112Z",
     "iopub.status.idle": "2024-08-25T15:00:16.492632Z",
     "shell.execute_reply": "2024-08-25T15:00:16.491683Z"
    },
    "papermill": {
     "duration": 28.781682,
     "end_time": "2024-08-25T15:00:16.495042",
     "exception": false,
     "start_time": "2024-08-25T14:59:47.713360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chardet\r\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\r\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: chardet\r\n",
      "Successfully installed chardet-5.2.0\r\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple/\r\n",
      "Collecting pycocotools\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/6a/03/6c0bf810a5df7876caaf11f5b113e7ffd4b2fa9767d360489c6fdcefe8e5/pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.8/427.8 kB\u001b[0m \u001b[31m486.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools) (3.7.5)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pycocotools) (1.26.4)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (4.47.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (21.3)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (9.5.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (2.9.0.post0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\r\n",
      "Installing collected packages: pycocotools\r\n",
      "Successfully installed pycocotools-2.0.8\r\n"
     ]
    }
   ],
   "source": [
    "!pip install chardet\n",
    "!pip install pycocotools -i https://pypi.tuna.tsinghua.edu.cn/simple/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c64cdbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T15:00:16.508951Z",
     "iopub.status.busy": "2024-08-25T15:00:16.508578Z",
     "iopub.status.idle": "2024-08-25T15:00:16.696205Z",
     "shell.execute_reply": "2024-08-25T15:00:16.695441Z"
    },
    "papermill": {
     "duration": 0.197268,
     "end_time": "2024-08-25T15:00:16.698614",
     "exception": false,
     "start_time": "2024-08-25T15:00:16.501346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "#bk_img = Book_Image('/kaggle/input/data-train/data_train/IMG_20191014_161641.json')\n",
    "#img=np.array(bk_img.image)\n",
    "\n",
    "\n",
    "def trans(image):\n",
    "    img=np.array(image)\n",
    "    # 形态学操作：膨胀，增强边缘\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    img = cv2.dilate(img, kernel, iterations=1)\n",
    "\n",
    "\n",
    "    gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "\n",
    "    # 步骤4: 边缘检测 - 使用Canny算法\n",
    "    edges = cv2.Canny(gray_image, threshold1=50, threshold2=150)\n",
    "    # 形态学开运算：先腐蚀再膨胀，用于断开边缘上的细节\n",
    "    opened_edges = cv2.morphologyEx(edges, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # 步骤5: 可选的轮廓处理\n",
    "    # 寻找轮廓\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contour_image = cv2.cvtColor(gray_image, cv2.COLOR_GRAY2BGR)\n",
    "    cv2.drawContours(contour_image, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "    # 绘制轮廓\n",
    "    contour_img = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)\n",
    "    cv2.drawContours(contour_img, contours, -1, (0, 255, 0), 2)\n",
    "    #cv2.imwrite('/kaggle/working/blurred_image.jpg', img_blurred)\n",
    "    #cv2.imwrite('/kaggle/working/edges.jpg', edges)\n",
    "    #cv2.imwrite('/kaggle/working/contours.jpg', contour_img)\n",
    "    #cv2.imwrite('/kaggle/working/contour_image.jpg', contour_image)\n",
    "    return contour_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "292d1777",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T15:00:16.712175Z",
     "iopub.status.busy": "2024-08-25T15:00:16.711846Z",
     "iopub.status.idle": "2024-08-25T15:00:22.125196Z",
     "shell.execute_reply": "2024-08-25T15:00:22.124205Z"
    },
    "papermill": {
     "duration": 5.422962,
     "end_time": "2024-08-25T15:00:22.127572",
     "exception": false,
     "start_time": "2024-08-25T15:00:16.704610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "from copy import deepcopy\n",
    "import chardet\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "from PIL import Image, ImageDraw\n",
    "import io\n",
    "import os\n",
    "from torchvision import tv_tensors\n",
    "\n",
    "class Book_Image():\n",
    "    def __init__(self,file_dir,with_mask=False,encode=r'ISO-8859-1'):\n",
    "        self.dir=dir\n",
    "        self.image_json=self.file_json(file_dir,encode)\n",
    "        self.image,self.shapes_list,self.masks,self.masks_boxes=self.load_image(self.image_json,with_mask=with_mask)\n",
    "        self.img_array=np.array(self.image)\n",
    "        self.trans_image=trans(self.image)\n",
    "    def file_json(self,file_dir,encode):\n",
    "        with open(os.path.join(file_dir), 'r', encoding=encode) as f:\n",
    "            image_json = json.loads(f.read())\n",
    "        return image_json\n",
    "    def load_image(self,image_json,with_mask=False):\n",
    "        base64_img_data=image_json['imageData']\n",
    "        img_data=base64.b64decode(base64_img_data)\n",
    "        shapes_list = [shape['points'] for shape in image_json['shapes']]\n",
    "        image=Image.open(io.BytesIO(img_data))\n",
    "        \n",
    "        masks=[]\n",
    "        masks_boxes = []\n",
    "        if with_mask == True:\n",
    "            for m in image_json['mask_data']:\n",
    "                m_data=base64.b64decode(m)\n",
    "                m_=Image.open(io.BytesIO(m_data)).convert('1')\n",
    "                masks.append(m_)\n",
    "                pos=np.where(m_)    #返回值为1，或为true的像素点的坐标 pos[0]是y，pos[1]是x\n",
    "                xmin=np.min(pos[1])\n",
    "                xmax=np.max(pos[1])\n",
    "                ymin=np.min(pos[0])\n",
    "                ymax=np.max(pos[0])\n",
    "                masks_boxes.append([xmin,ymin,xmax,ymax])\n",
    "        return image,shapes_list,masks,masks_boxes\n",
    "    def show(self):\n",
    "        self.image.show()\n",
    "    def draw_boxes(self):\n",
    "        if self.image!=None:\n",
    "            draw=ImageDraw.Draw(self.image)\n",
    "            for s in self.shapes_list:\n",
    "                p_count = len(s)\n",
    "                for idx in range(p_count):\n",
    "                    draw.line((s[idx % p_count][0], s[idx % p_count][1], s[(idx + 1) % p_count][0],\n",
    "                               s[(idx + 1) % p_count][1]), fill=(255, 0, 0), width=5)\n",
    "    def draw_masks(self):\n",
    "        if self.image!=None:\n",
    "            another_image=deepcopy(self.image)\n",
    "            draw=ImageDraw.Draw(another_image)\n",
    "            for s in self.shapes_list:\n",
    "                #mask_array=np.zeros(self.img_array.shape[:2],dtype=np.uint8)    #np.uint8 无符号数\n",
    "                polygon=[tuple(idx) for idx in s]\n",
    "                draw.polygon(polygon,fill=(255,255,255),outline=None,width=0)\n",
    "            return another_image\n",
    "    def get_masks(self):\n",
    "        if self.image!=None:\n",
    "            mask_list=list()\n",
    "            for s in self.shapes_list:\n",
    "                # mask_array=np.zeros(self.img_array.shape[:2],dtype=np.uint8)    #np.uint8 无符号数\n",
    "                mask = Image.new('L', self.image.size, color=0)\n",
    "                draw = ImageDraw.Draw(mask)\n",
    "                polygon = [tuple(idx) for idx in s]\n",
    "                draw.polygon(polygon, fill=255, outline=None, width=0)\n",
    "            #mask.convert('1').show()\n",
    "                mask_list.append(mask)\n",
    "            return mask_list\n",
    "\n",
    "class Book_Spine_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,root):\n",
    "        self.root=root\n",
    "        self.imgs= list(sorted(os.listdir(self.root)))\n",
    "    def __getitem__(self, idx):\n",
    "        bk_img = Book_Image(os.path.join(self.root, self.imgs[idx]), with_mask=True, encode='utf-8')\n",
    "\n",
    "        # Wrap sample and targets into torchvision tv_tensors:\n",
    "        image = torch.as_tensor(np.array(bk_img.trans_image, dtype=np.uint8), dtype=torch.float32)\n",
    "        image = image.permute(2, 0, 1).div(255)\n",
    "\n",
    "        num_objs = len(bk_img.masks)\n",
    "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
    "        m_boxes = torch.as_tensor(bk_img.masks_boxes, dtype=torch.float32)\n",
    "        area = (m_boxes[:, 3] - m_boxes[:, 1]) * (m_boxes[:, 2] - m_boxes[:, 0])\n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.ones((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target['boxes'] = m_boxes\n",
    "        target['labels'] = labels\n",
    "        target['masks'] = torch.as_tensor(\n",
    "            np.array([np.array(m.convert('1'), dtype=np.uint8) for m in bk_img.masks], dtype=np.uint8),\n",
    "            dtype=torch.uint8)\n",
    "        target['image_id'] = self.imgs[idx]\n",
    "        target['area'] = area\n",
    "        target['iscrowd'] = iscrowd\n",
    "        return image, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a19a6457",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T15:00:22.141424Z",
     "iopub.status.busy": "2024-08-25T15:00:22.140968Z",
     "iopub.status.idle": "2024-08-25T15:00:22.147441Z",
     "shell.execute_reply": "2024-08-25T15:00:22.146627Z"
    },
    "papermill": {
     "duration": 0.015666,
     "end_time": "2024-08-25T15:00:22.149368",
     "exception": false,
     "start_time": "2024-08-25T15:00:22.133702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "\n",
    "def get_model_instance_segmentation(num_classes):\n",
    "    # load an instance segmentation model pre-trained on COCO\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "\n",
    "    # get number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    # now get the number of input features for the mask classifier\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    # and replace the mask predictor with a new one\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(\n",
    "        in_features_mask,\n",
    "        hidden_layer,\n",
    "        num_classes\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fddf211",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T15:00:22.162340Z",
     "iopub.status.busy": "2024-08-25T15:00:22.161730Z",
     "iopub.status.idle": "2024-08-25T15:06:12.912335Z",
     "shell.execute_reply": "2024-08-25T15:06:12.911316Z"
    },
    "papermill": {
     "duration": 350.759261,
     "end_time": "2024-08-25T15:06:12.914358",
     "exception": false,
     "start_time": "2024-08-25T15:00:22.155097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\" to /root/.cache/torch/hub/checkpoints/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\n",
      "100%|██████████| 170M/170M [00:01<00:00, 161MB/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [ 0/24]  eta: 0:06:09  lr: 0.000013  loss: 4.2297 (4.2297)  loss_classifier: 0.8788 (0.8788)  loss_box_reg: 0.9098 (0.9098)  loss_mask: 1.7894 (1.7894)  loss_objectness: 0.2999 (0.2999)  loss_rpn_box_reg: 0.3519 (0.3519)  time: 15.3783  data: 12.7661  max mem: 7255\n",
      "Epoch: [0]  [ 5/24]  eta: 0:04:37  lr: 0.000078  loss: 4.1836 (4.2329)  loss_classifier: 0.8542 (0.8564)  loss_box_reg: 0.8974 (0.8894)  loss_mask: 1.7894 (1.9965)  loss_objectness: 0.1224 (0.1806)  loss_rpn_box_reg: 0.3323 (0.3100)  time: 14.6294  data: 13.1181  max mem: 7759\n",
      "Epoch: [0]  [10/24]  eta: 0:03:22  lr: 0.000144  loss: 3.5387 (3.7812)  loss_classifier: 0.8330 (0.8152)  loss_box_reg: 0.8956 (0.8846)  loss_mask: 1.3883 (1.6479)  loss_objectness: 0.0933 (0.1249)  loss_rpn_box_reg: 0.3274 (0.3086)  time: 14.4538  data: 13.0437  max mem: 7759\n",
      "Epoch: [0]  [15/24]  eta: 0:02:10  lr: 0.000209  loss: 3.2815 (3.5091)  loss_classifier: 0.7715 (0.7719)  loss_box_reg: 0.8945 (0.8856)  loss_mask: 1.2663 (1.4550)  loss_objectness: 0.0530 (0.0984)  loss_rpn_box_reg: 0.3262 (0.2982)  time: 14.4896  data: 13.1170  max mem: 7774\n",
      "Epoch: [0]  [20/24]  eta: 0:00:57  lr: 0.000274  loss: 3.0563 (3.2767)  loss_classifier: 0.7294 (0.7292)  loss_box_reg: 0.8843 (0.8823)  loss_mask: 1.0663 (1.2885)  loss_objectness: 0.0469 (0.0835)  loss_rpn_box_reg: 0.2993 (0.2933)  time: 14.4554  data: 13.1661  max mem: 7774\n",
      "Epoch: [0]  [23/24]  eta: 0:00:14  lr: 0.000300  loss: 2.8755 (3.1742)  loss_classifier: 0.6541 (0.7076)  loss_box_reg: 0.8745 (0.8763)  loss_mask: 0.9998 (1.2214)  loss_objectness: 0.0407 (0.0814)  loss_rpn_box_reg: 0.2834 (0.2874)  time: 14.4343  data: 13.1465  max mem: 7774\n",
      "Epoch: [0] Total time: 0:05:47 (14.4956 s / it)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [05:48<00:00, 348.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "from engine import train_one_epoch,evaluate\n",
    "from tqdm import tqdm\n",
    "def start_train():\n",
    "    torch.cuda.empty_cache()\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "    model = get_model_instance_segmentation(2)\n",
    "    #print(model)\n",
    "    model.to(device)  ##将模型加载到处理器中\n",
    "    dataset= Book_Spine_Dataset('/kaggle/input/data-train/data_train')\n",
    "\n",
    "    ###将数据集切分为训练集和测试集\n",
    "    indices = torch.randperm(len(dataset)).tolist()  ##生成随机数索引的列表\n",
    "    dataset_for_train= torch.utils.data.Subset(dataset, indices[:120])  #根据随机索引切分子集    Subset(数据集,索引列表)\n",
    "    dataset_for_test = torch.utils.data.Subset(dataset, indices[120:])\n",
    "\n",
    "    ###data_loader用于训练时迭代加载数据集\n",
    "    data_loader=torch.utils.data.DataLoader(dataset_for_train,batch_size=5,shuffle=True,collate_fn=utils.collate_fn)\n",
    "    data_loader_test=torch.utils.data.DataLoader(dataset_for_test,batch_size=1,shuffle=False,collate_fn=utils.collate_fn)\n",
    "\n",
    "\n",
    "\n",
    "    params=[p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer=torch.optim.SGD(params,lr=0.0003,momentum=0.5,weight_decay=0.0005)\n",
    "\n",
    "    lr_scheduler=torch.optim.lr_scheduler.StepLR(optimizer,step_size=2,gamma=0.1)\n",
    "\n",
    "    num_epochs=1\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        train_one_epoch(model,optimizer,data_loader,device,epoch,print_freq=5)\n",
    "        model.eval()\n",
    "        torch.save(model,f'/kaggle/working/bk_spine_segmentation{epoch}.pth')\n",
    "        lr_scheduler.step()\n",
    "        #evaluate(model,data_loader_test,device=device)\n",
    "    print(\"That's it\")\n",
    "start_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b4d3db5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T15:06:12.933397Z",
     "iopub.status.busy": "2024-08-25T15:06:12.932791Z",
     "iopub.status.idle": "2024-08-25T15:06:16.183794Z",
     "shell.execute_reply": "2024-08-25T15:06:16.182720Z"
    },
    "papermill": {
     "duration": 3.264256,
     "end_time": "2024-08-25T15:06:16.186792",
     "exception": false,
     "start_time": "2024-08-25T15:06:12.922536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting\n",
      "{'boxes': tensor([[2.7579e+03, 0.0000e+00, 2.9261e+03, 2.1397e+03],\n",
      "        [8.4804e+02, 1.6313e+03, 8.9802e+02, 1.7976e+03],\n",
      "        [5.6703e+02, 0.0000e+00, 3.9382e+03, 4.1034e+02],\n",
      "        [2.4802e+03, 0.0000e+00, 2.8317e+03, 3.0240e+03],\n",
      "        [1.1522e+02, 7.3616e+01, 4.5195e+02, 3.0240e+03],\n",
      "        [2.7781e+03, 3.2408e+00, 2.8996e+03, 1.2241e+03],\n",
      "        [2.5681e+03, 0.0000e+00, 2.7485e+03, 1.9846e+03],\n",
      "        [1.8620e+03, 1.0612e+01, 2.0067e+03, 3.0240e+03],\n",
      "        [3.9114e+03, 2.6719e+03, 4.0053e+03, 3.0069e+03],\n",
      "        [2.8230e+03, 0.0000e+00, 2.9217e+03, 1.3578e+03],\n",
      "        [2.9524e+03, 0.0000e+00, 3.1997e+03, 3.0240e+03],\n",
      "        [2.8293e+03, 2.1893e+01, 3.0071e+03, 2.3261e+03],\n",
      "        [2.6302e+03, 1.4528e+02, 2.9821e+03, 3.0240e+03],\n",
      "        [7.5507e+01, 1.5142e+02, 1.0745e+02, 1.8837e+02],\n",
      "        [8.1970e+02, 1.6220e+03, 8.7364e+02, 1.8081e+03],\n",
      "        [3.7222e+03, 3.8624e+01, 3.8852e+03, 2.6576e+03],\n",
      "        [2.6776e+03, 9.2841e+00, 2.7704e+03, 1.1724e+03],\n",
      "        [7.7269e+01, 1.3477e+02, 1.0336e+02, 1.7099e+02],\n",
      "        [2.6613e+03, 1.2162e+02, 2.7440e+03, 1.3737e+03],\n",
      "        [3.6130e+03, 6.2577e+01, 3.9299e+03, 2.1985e+03],\n",
      "        [5.3836e+02, 1.3429e+01, 9.0502e+02, 2.8567e+03],\n",
      "        [8.1149e+02, 0.0000e+00, 9.7510e+02, 2.2975e+03],\n",
      "        [4.1071e+02, 1.8112e+01, 1.2446e+03, 2.8303e+03],\n",
      "        [0.0000e+00, 1.6592e+00, 2.3075e+03, 2.4796e+02],\n",
      "        [2.2120e+03, 0.0000e+00, 3.9598e+03, 4.3387e+02],\n",
      "        [1.9008e+03, 1.5489e+01, 2.2191e+03, 3.0240e+03],\n",
      "        [5.5291e+01, 6.4404e+02, 8.2411e+01, 6.7111e+02],\n",
      "        [7.2488e+02, 0.0000e+00, 1.0245e+03, 2.8941e+03],\n",
      "        [2.0869e+03, 0.0000e+00, 2.2548e+03, 2.6584e+03],\n",
      "        [3.0882e+02, 2.8951e+01, 6.1114e+02, 3.0240e+03],\n",
      "        [8.0129e+02, 1.6355e+03, 9.0295e+02, 1.7802e+03],\n",
      "        [3.0100e+03, 0.0000e+00, 3.0900e+03, 1.6087e+03],\n",
      "        [1.9540e+03, 0.0000e+00, 2.1473e+03, 2.4844e+03],\n",
      "        [2.0786e+03, 1.3073e+01, 2.6560e+03, 3.0240e+03],\n",
      "        [3.6237e+03, 2.3074e+03, 3.8013e+03, 3.0240e+03],\n",
      "        [3.5210e+03, 5.3517e+01, 3.7616e+03, 2.9335e+03],\n",
      "        [3.3311e+01, 0.0000e+00, 1.5104e+03, 6.2483e+02],\n",
      "        [2.6133e+03, 1.1034e+02, 2.7135e+03, 1.3346e+03],\n",
      "        [1.6899e+03, 1.1668e+02, 1.9100e+03, 2.9794e+03],\n",
      "        [3.3145e+03, 0.0000e+00, 3.8600e+03, 3.0240e+03],\n",
      "        [9.5835e+00, 1.0150e+02, 2.1592e+03, 3.0240e+03],\n",
      "        [2.1623e+03, 0.0000e+00, 2.3191e+03, 2.5944e+03],\n",
      "        [1.2975e+03, 5.0445e+01, 1.6122e+03, 3.0240e+03],\n",
      "        [3.8540e+03, 0.0000e+00, 3.9988e+03, 3.0240e+03],\n",
      "        [2.1636e+01, 1.1514e+02, 3.1483e+02, 2.9914e+03],\n",
      "        [2.9006e+01, 6.4961e+02, 5.7282e+01, 6.7767e+02],\n",
      "        [1.8811e+03, 2.9277e+03, 2.0937e+03, 3.0240e+03],\n",
      "        [2.3382e+03, 0.0000e+00, 2.6027e+03, 2.8034e+03],\n",
      "        [1.1750e+03, 0.0000e+00, 1.3423e+03, 2.4790e+03],\n",
      "        [1.9664e+03, 2.4410e+01, 3.9690e+03, 3.0240e+03],\n",
      "        [8.8504e+02, 0.0000e+00, 1.7075e+03, 3.0240e+03],\n",
      "        [1.4032e+03, 0.0000e+00, 1.9893e+03, 3.0240e+03],\n",
      "        [1.9086e+02, 1.6442e+02, 9.3576e+02, 2.8470e+03],\n",
      "        [3.5371e+03, 2.9806e+03, 3.9208e+03, 3.0225e+03],\n",
      "        [2.8955e+03, 4.9285e+00, 3.0885e+03, 2.3441e+03],\n",
      "        [5.4228e+02, 0.0000e+00, 7.2163e+02, 2.0783e+03],\n",
      "        [2.6775e+03, 1.1216e+02, 3.3187e+03, 3.0240e+03],\n",
      "        [1.9714e+03, 5.7624e+01, 2.1175e+03, 8.3131e+02],\n",
      "        [3.7984e+03, 2.7021e+03, 4.0213e+03, 3.0041e+03],\n",
      "        [2.7070e+03, 3.4559e+02, 2.7652e+03, 8.6057e+02],\n",
      "        [3.5584e+03, 2.3054e+01, 3.6936e+03, 2.2217e+03],\n",
      "        [8.2944e+02, 5.9354e+01, 1.0973e+03, 3.0240e+03],\n",
      "        [9.7946e+02, 0.0000e+00, 1.1600e+03, 2.3190e+03],\n",
      "        [7.4126e+01, 2.0482e+02, 1.0167e+02, 2.4153e+02],\n",
      "        [2.2039e+03, 2.8203e+03, 2.2535e+03, 3.0240e+03],\n",
      "        [5.3368e+02, 2.8846e+03, 7.1020e+02, 3.0240e+03],\n",
      "        [3.9565e+03, 2.6797e+03, 4.0117e+03, 3.0240e+03],\n",
      "        [2.4558e+03, 9.8407e+00, 2.5897e+03, 2.1784e+03],\n",
      "        [1.6477e+03, 0.0000e+00, 1.7944e+03, 2.5858e+03],\n",
      "        [9.7273e+02, 6.1433e+01, 1.2535e+03, 3.0117e+03],\n",
      "        [3.5036e+02, 8.6529e+00, 5.2275e+02, 2.0316e+03],\n",
      "        [1.5534e+03, 3.1432e+02, 2.3319e+03, 3.0240e+03],\n",
      "        [2.9445e+03, 0.0000e+00, 3.4591e+03, 3.0240e+03],\n",
      "        [7.0682e+01, 6.3253e+02, 9.8889e+01, 6.6088e+02],\n",
      "        [3.2564e+03, 7.4863e+01, 3.5361e+03, 3.0240e+03],\n",
      "        [2.2582e+03, 0.0000e+00, 2.4418e+03, 2.3928e+03],\n",
      "        [5.2669e+02, 1.6282e+03, 8.6406e+02, 3.0240e+03],\n",
      "        [3.6520e+03, 3.7459e+01, 3.8225e+03, 2.5619e+03],\n",
      "        [8.8519e+02, 2.5696e+02, 2.9702e+03, 3.0240e+03],\n",
      "        [3.8086e+03, 2.5619e+03, 3.8765e+03, 3.0240e+03],\n",
      "        [3.1077e+03, 0.0000e+00, 3.2631e+03, 2.5694e+03],\n",
      "        [4.3245e+01, 6.6442e+02, 6.7797e+01, 6.8820e+02],\n",
      "        [3.5813e+03, 2.7009e+03, 3.8129e+03, 3.0008e+03],\n",
      "        [7.1679e+01, 1.0396e+02, 1.0390e+02, 1.4259e+02],\n",
      "        [7.7548e+01, 6.3404e+02, 1.1039e+02, 6.7182e+02],\n",
      "        [6.6032e+01, 6.5947e+02, 9.8826e+01, 6.9141e+02],\n",
      "        [2.2171e+03, 2.6748e+03, 2.2756e+03, 3.0240e+03],\n",
      "        [2.7301e+03, 2.3303e+01, 2.8271e+03, 1.1599e+03],\n",
      "        [3.5433e+03, 2.4357e+03, 3.5947e+03, 3.0240e+03],\n",
      "        [3.0383e+03, 1.5353e+01, 3.1653e+03, 2.9012e+03],\n",
      "        [7.5868e+02, 1.0493e+03, 9.0234e+02, 1.2158e+03],\n",
      "        [1.2232e+03, 0.0000e+00, 1.2980e+03, 1.6198e+03],\n",
      "        [1.7979e+03, 1.0402e+02, 2.1319e+03, 2.7372e+03],\n",
      "        [5.8307e+02, 5.5125e+01, 6.8706e+02, 1.2544e+03],\n",
      "        [3.5446e+03, 2.9701e+03, 3.7331e+03, 3.0240e+03],\n",
      "        [2.3848e+03, 2.9551e+03, 2.5834e+03, 3.0240e+03],\n",
      "        [4.9638e+02, 8.3179e+02, 6.8902e+02, 3.0240e+03],\n",
      "        [1.1893e+03, 5.1600e+01, 1.4541e+03, 2.9111e+03],\n",
      "        [6.8123e+02, 0.0000e+00, 7.8041e+02, 1.3356e+03],\n",
      "        [3.4589e+03, 2.8947e+03, 3.6000e+03, 3.0240e+03]], device='cuda:0'), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1], device='cuda:0'), 'scores': tensor([0.5307, 0.4831, 0.4692, 0.4600, 0.4594, 0.4588, 0.4583, 0.4565, 0.4512,\n",
      "        0.4500, 0.4484, 0.4467, 0.4451, 0.4382, 0.4373, 0.4344, 0.4336, 0.4336,\n",
      "        0.4333, 0.4319, 0.4258, 0.4246, 0.4229, 0.4218, 0.4214, 0.4196, 0.4188,\n",
      "        0.4165, 0.4164, 0.4134, 0.4129, 0.4113, 0.4109, 0.4096, 0.4073, 0.4069,\n",
      "        0.4068, 0.4059, 0.4039, 0.4022, 0.4016, 0.4016, 0.4016, 0.4015, 0.3997,\n",
      "        0.3973, 0.3972, 0.3965, 0.3948, 0.3933, 0.3909, 0.3891, 0.3888, 0.3882,\n",
      "        0.3873, 0.3873, 0.3869, 0.3850, 0.3837, 0.3833, 0.3815, 0.3815, 0.3791,\n",
      "        0.3788, 0.3780, 0.3779, 0.3757, 0.3754, 0.3746, 0.3741, 0.3736, 0.3728,\n",
      "        0.3725, 0.3712, 0.3706, 0.3702, 0.3701, 0.3693, 0.3682, 0.3679, 0.3675,\n",
      "        0.3667, 0.3665, 0.3632, 0.3619, 0.3619, 0.3618, 0.3615, 0.3582, 0.3582,\n",
      "        0.3579, 0.3574, 0.3572, 0.3568, 0.3562, 0.3552, 0.3551, 0.3550, 0.3543,\n",
      "        0.3538], device='cuda:0'), 'masks': tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0')}\n",
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n",
      "[2778.0688, 3.2407663, 2899.6396, 1224.074]\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "def just_a_try():\n",
    "    bk_img=Book_Image('/kaggle/input/data-train/data_train/IMG_20191014_161649.json',with_mask=True,encode='utf-8')\n",
    "    \n",
    "    image = torch.as_tensor(np.array(bk_img.trans_image, dtype=np.uint8), dtype=torch.float32)\n",
    "    image = image.permute(2, 0, 1).div(255)\n",
    "        \n",
    "    # Wrap sample and targets into torchvision tv_tensors:\n",
    "    #print(image)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "    \n",
    "    model = torch.load('/kaggle/working/bk_spine_segmentation0.pth')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print('predicting')\n",
    "    with torch.no_grad():\n",
    "        output = model([image.to(device)])\n",
    "        pred = output[0]\n",
    "    \n",
    "    masks = (pred[\"masks\"] > 0.7).squeeze(1)\n",
    "    print(pred)\n",
    "\n",
    "    mm=masks[0].cpu().numpy()\n",
    "    mi=Image.fromarray(mm,mode='L')\n",
    "    mi.save('/kaggle/working/mask.jpeg',format='jpeg')\n",
    "    print(mm)\n",
    "    box=list(pred['boxes'][5].cpu().numpy())\n",
    "    print(box)\n",
    "\n",
    "    draw=ImageDraw.Draw(bk_img.image)\n",
    "    draw.rectangle(box,fill=(255,255,255),outline=None,width=0)\n",
    "    bk_img.image.save('/kaggle/working/toshow_image.jpeg',format='jpeg')\n",
    "just_a_try()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5564838,
     "sourceId": 9203856,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5564890,
     "sourceId": 9203932,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 107074,
     "modelInstanceId": 82775,
     "sourceId": 98657,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 394.316286,
   "end_time": "2024-08-25T15:06:18.564902",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-25T14:59:44.248616",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
