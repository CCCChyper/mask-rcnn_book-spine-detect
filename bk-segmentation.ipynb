{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9203856,"sourceType":"datasetVersion","datasetId":5564838},{"sourceId":9203932,"sourceType":"datasetVersion","datasetId":5564890},{"sourceId":98657,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":82775,"modelId":107074}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-27T12:01:59.832329Z","iopub.execute_input":"2024-08-27T12:01:59.833120Z","iopub.status.idle":"2024-08-27T12:02:00.952706Z","shell.execute_reply.started":"2024-08-27T12:01:59.833081Z","shell.execute_reply":"2024-08-27T12:02:00.951748Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import sys\nif('/kaggle/input/references') not in sys.path:\n    print(sys.path.append('/kaggle/input/references'))\n    print('Adding cite path is done')\nelse:\n    print('Cite path added')","metadata":{"execution":{"iopub.status.busy":"2024-08-27T12:02:00.954393Z","iopub.execute_input":"2024-08-27T12:02:00.954928Z","iopub.status.idle":"2024-08-27T12:02:00.961199Z","shell.execute_reply.started":"2024-08-27T12:02:00.954899Z","shell.execute_reply":"2024-08-27T12:02:00.960117Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"None\nAdding cite path is done\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install chardet\n!pip install pycocotools -i https://pypi.tuna.tsinghua.edu.cn/simple/","metadata":{"execution":{"iopub.status.busy":"2024-08-27T12:02:00.962596Z","iopub.execute_input":"2024-08-27T12:02:00.962977Z","iopub.status.idle":"2024-08-27T12:02:33.800795Z","shell.execute_reply.started":"2024-08-27T12:02:00.962940Z","shell.execute_reply":"2024-08-27T12:02:33.799172Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting chardet\n  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\nDownloading chardet-5.2.0-py3-none-any.whl (199 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: chardet\nSuccessfully installed chardet-5.2.0\nLooking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple/\nCollecting pycocotools\n  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/6a/03/6c0bf810a5df7876caaf11f5b113e7ffd4b2fa9767d360489c6fdcefe8e5/pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.8/427.8 kB\u001b[0m \u001b[31m489.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools) (3.7.5)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pycocotools) (1.26.4)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\nInstalling collected packages: pycocotools\nSuccessfully installed pycocotools-2.0.8\n","output_type":"stream"}]},{"cell_type":"code","source":"#书脊图像transform\n\nfrom PIL import Image\nimport cv2\n#bk_img = Book_Image('/kaggle/input/data-train/data_train/IMG_20191014_161641.json')\n#img=np.array(bk_img.image)\n\n\ndef trans(image):\n    img=np.array(image)\n    # 形态学操作：膨胀，增强边缘\n    kernel = np.ones((3, 3), np.uint8)\n    img = cv2.dilate(img, kernel, iterations=1)\n\n\n    gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    \n\n    # 步骤4: 边缘检测 - 使用Canny算法\n    edges = cv2.Canny(gray_image, threshold1=50, threshold2=150)\n    # 形态学开运算：先腐蚀再膨胀，用于断开边缘上的细节\n    opened_edges = cv2.morphologyEx(edges, cv2.MORPH_OPEN, kernel)\n\n    # 步骤5: 可选的轮廓处理\n    # 寻找轮廓\n    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    contour_image = cv2.cvtColor(gray_image, cv2.COLOR_GRAY2BGR)\n    cv2.drawContours(contour_image, contours, -1, (0, 255, 0), 2)\n\n    # 绘制轮廓\n    contour_img = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)\n    cv2.drawContours(contour_img, contours, -1, (0, 255, 0), 2)\n    #cv2.imwrite('/kaggle/working/blurred_image.jpg', img_blurred)\n    #cv2.imwrite('/kaggle/working/edges.jpg', edges)\n    #cv2.imwrite('/kaggle/working/contours.jpg', contour_img)\n    #cv2.imwrite('/kaggle/working/contour_image.jpg', contour_image)\n    return contour_image","metadata":{"execution":{"iopub.status.busy":"2024-08-27T12:02:33.803563Z","iopub.execute_input":"2024-08-27T12:02:33.803912Z","iopub.status.idle":"2024-08-27T12:02:34.038387Z","shell.execute_reply.started":"2024-08-27T12:02:33.803879Z","shell.execute_reply":"2024-08-27T12:02:34.037495Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#加载图像dataset\nimport base64\nimport json\nfrom copy import deepcopy\nimport chardet\nimport cv2\nimport numpy as np\nimport torch.utils.data\nfrom PIL import Image, ImageDraw\nimport io\nimport os\nfrom torchvision import tv_tensors\n\nclass Book_Image():\n    def __init__(self,file_dir,with_mask=False,encode=r'ISO-8859-1'):\n        self.dir=dir\n        self.image_json=self.file_json(file_dir,encode)\n        self.image,self.shapes_list,self.masks,self.masks_boxes=self.load_image(self.image_json,with_mask=with_mask)\n        self.img_array=np.array(self.image)\n        self.trans_image=trans(self.image)\n    def file_json(self,file_dir,encode):\n        with open(os.path.join(file_dir), 'r', encoding=encode) as f:\n            image_json = json.loads(f.read())\n        return image_json\n    def load_image(self,image_json,with_mask=False):\n        base64_img_data=image_json['imageData']\n        img_data=base64.b64decode(base64_img_data)\n        shapes_list = [shape['points'] for shape in image_json['shapes']]\n        image=Image.open(io.BytesIO(img_data))\n        \n        masks=[]\n        masks_boxes = []\n        if with_mask == True:\n            for m in image_json['mask_data']:\n                m_data=base64.b64decode(m)\n                m_=Image.open(io.BytesIO(m_data)).convert('1')\n                masks.append(m_)\n                pos=np.where(m_)    #返回值为1，或为true的像素点的坐标 pos[0]是y，pos[1]是x\n                xmin=np.min(pos[1])\n                xmax=np.max(pos[1])\n                ymin=np.min(pos[0])\n                ymax=np.max(pos[0])\n                masks_boxes.append([xmin,ymin,xmax,ymax])\n        return image,shapes_list,masks,masks_boxes\n    def show(self):\n        self.image.show()\n    def draw_boxes(self):\n        if self.image!=None:\n            draw=ImageDraw.Draw(self.image)\n            for s in self.shapes_list:\n                p_count = len(s)\n                for idx in range(p_count):\n                    draw.line((s[idx % p_count][0], s[idx % p_count][1], s[(idx + 1) % p_count][0],\n                               s[(idx + 1) % p_count][1]), fill=(255, 0, 0), width=5)\n    def draw_masks(self):\n        if self.image!=None:\n            another_image=deepcopy(self.image)\n            draw=ImageDraw.Draw(another_image)\n            for s in self.shapes_list:\n                #mask_array=np.zeros(self.img_array.shape[:2],dtype=np.uint8)    #np.uint8 无符号数\n                polygon=[tuple(idx) for idx in s]\n                draw.polygon(polygon,fill=(255,255,255),outline=None,width=0)\n            return another_image\n    def get_masks(self):\n        if self.image!=None:\n            mask_list=list()\n            for s in self.shapes_list:\n                # mask_array=np.zeros(self.img_array.shape[:2],dtype=np.uint8)    #np.uint8 无符号数\n                mask = Image.new('L', self.image.size, color=0)\n                draw = ImageDraw.Draw(mask)\n                polygon = [tuple(idx) for idx in s]\n                draw.polygon(polygon, fill=255, outline=None, width=0)\n            #mask.convert('1').show()\n                mask_list.append(mask)\n            return mask_list\n\nclass Book_Spine_Dataset(torch.utils.data.Dataset):\n    def __init__(self,root):\n        self.root=root\n        self.imgs= list(sorted(os.listdir(self.root)))\n    def __getitem__(self, idx):\n        bk_img = Book_Image(os.path.join(self.root, self.imgs[idx]), with_mask=True, encode='utf-8')\n\n        # Wrap sample and targets into torchvision tv_tensors:\n        image = torch.as_tensor(np.array(bk_img.trans_image, dtype=np.uint8), dtype=torch.float32)\n        image = image.permute(2, 0, 1).div(255)\n\n        num_objs = len(bk_img.masks)\n        labels = torch.ones((num_objs,), dtype=torch.int64)\n        m_boxes = torch.as_tensor(bk_img.masks_boxes, dtype=torch.float32)\n        area = (m_boxes[:, 3] - m_boxes[:, 1]) * (m_boxes[:, 2] - m_boxes[:, 0])\n        # suppose all instances are not crowd\n        iscrowd = torch.ones((num_objs,), dtype=torch.int64)\n\n        target = {}\n        target['boxes'] = m_boxes\n        target['labels'] = labels\n        target['masks'] = torch.as_tensor(\n            np.array([np.array(m.convert('1'), dtype=np.uint8) for m in bk_img.masks], dtype=np.uint8),\n            dtype=torch.uint8)\n        target['image_id'] = self.imgs[idx]\n        target['area'] = area\n        target['iscrowd'] = iscrowd\n        return image, target\n\n    def __len__(self):\n        return len(self.imgs)","metadata":{"execution":{"iopub.status.busy":"2024-08-27T12:02:34.039633Z","iopub.execute_input":"2024-08-27T12:02:34.039930Z","iopub.status.idle":"2024-08-27T12:02:39.687976Z","shell.execute_reply.started":"2024-08-27T12:02:34.039904Z","shell.execute_reply":"2024-08-27T12:02:39.687068Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#加载pretrain mask-rcnn模型\nimport torchvision\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n\n\ndef get_model_instance_segmentation(num_classes):\n    # load an instance segmentation model pre-trained on COCO\n    model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n\n    # get number of input features for the classifier\n    in_features = model.roi_heads.box_predictor.cls_score.in_features\n    # replace the pre-trained head with a new one\n    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n\n    # now get the number of input features for the mask classifier\n    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n    hidden_layer = 256\n    # and replace the mask predictor with a new one\n    model.roi_heads.mask_predictor = MaskRCNNPredictor(\n        in_features_mask,\n        hidden_layer,\n        num_classes\n    )\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-08-27T12:02:39.689163Z","iopub.execute_input":"2024-08-27T12:02:39.689656Z","iopub.status.idle":"2024-08-27T12:02:39.696969Z","shell.execute_reply.started":"2024-08-27T12:02:39.689626Z","shell.execute_reply":"2024-08-27T12:02:39.695865Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#开始train\n\nimport utils\nfrom engine import train_one_epoch,evaluate\nfrom tqdm import tqdm\ndef start_train():\n    torch.cuda.empty_cache()\n    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\n    model = get_model_instance_segmentation(2)\n    #print(model)\n    model.to(device)  ##将模型加载到处理器中\n    dataset= Book_Spine_Dataset('/kaggle/input/data-train/data_train')\n\n    ###将数据集切分为训练集和测试集\n    indices = torch.randperm(len(dataset)).tolist()  ##生成随机数索引的列表\n    dataset_for_train= torch.utils.data.Subset(dataset, indices[:400])  #根据随机索引切分子集    Subset(数据集,索引列表)\n    dataset_for_test = torch.utils.data.Subset(dataset, indices[400:450])\n\n    ###data_loader用于训练时迭代加载数据集\n    data_loader=torch.utils.data.DataLoader(dataset_for_train,batch_size=5,shuffle=True,collate_fn=utils.collate_fn)\n    data_loader_test=torch.utils.data.DataLoader(dataset_for_test,batch_size=1,shuffle=False,collate_fn=utils.collate_fn)\n\n    params=[p for p in model.parameters() if p.requires_grad]\n    optimizer=torch.optim.SGD(params,lr=0.0003,momentum=0.5,weight_decay=0.0005)\n\n    lr_scheduler=torch.optim.lr_scheduler.StepLR(optimizer,step_size=2,gamma=0.1)\n\n    num_epochs=1\n\n    for epoch in tqdm(range(num_epochs)):\n        train_one_epoch(model,optimizer,data_loader,device,epoch,print_freq=5)\n        model.eval()\n        torch.save(model,f'/kaggle/working/bk_spine_segmentation{epoch}.pth')\n        lr_scheduler.step()\n        evaluate(model,data_loader_test,device=device)\n    print(\"That's it\")\n    print(indices[400:410])\n#start_train()","metadata":{"execution":{"iopub.status.busy":"2024-08-27T12:02:39.698169Z","iopub.execute_input":"2024-08-27T12:02:39.698480Z","iopub.status.idle":"2024-08-27T13:16:05.412808Z","shell.execute_reply.started":"2024-08-27T12:02:39.698456Z","shell.execute_reply":"2024-08-27T13:16:05.411023Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\" to /root/.cache/torch/hub/checkpoints/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\n100%|██████████| 170M/170M [00:01<00:00, 146MB/s]  \n  0%|          | 0/1 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: [0]  [ 0/80]  eta: 0:26:11  lr: 0.000004  loss: 6.1496 (6.1496)  loss_classifier: 0.6151 (0.6151)  loss_box_reg: 0.9023 (0.9023)  loss_mask: 4.1521 (4.1521)  loss_objectness: 0.1227 (0.1227)  loss_rpn_box_reg: 0.3573 (0.3573)  time: 19.6422  data: 16.6227  max mem: 7400\nEpoch: [0]  [ 5/80]  eta: 0:21:06  lr: 0.000023  loss: 5.5518 (5.6788)  loss_classifier: 0.6151 (0.6133)  loss_box_reg: 0.9708 (0.9633)  loss_mask: 3.6095 (3.6461)  loss_objectness: 0.1227 (0.1393)  loss_rpn_box_reg: 0.3047 (0.3167)  time: 16.8872  data: 15.2813  max mem: 7784\nEpoch: [0]  [10/80]  eta: 0:19:23  lr: 0.000042  loss: 5.2876 (5.3717)  loss_classifier: 0.6122 (0.6120)  loss_box_reg: 0.9708 (0.9575)  loss_mask: 3.2625 (3.3236)  loss_objectness: 0.1227 (0.1445)  loss_rpn_box_reg: 0.3218 (0.3341)  time: 16.6229  data: 15.1511  max mem: 7784\nEpoch: [0]  [15/80]  eta: 0:17:47  lr: 0.000061  loss: 5.1198 (5.2075)  loss_classifier: 0.6060 (0.6081)  loss_box_reg: 0.9708 (0.9633)  loss_mask: 3.0531 (3.2074)  loss_objectness: 0.0763 (0.1118)  loss_rpn_box_reg: 0.3047 (0.3169)  time: 16.4201  data: 14.9995  max mem: 7784\nEpoch: [0]  [20/80]  eta: 0:16:11  lr: 0.000080  loss: 4.9091 (4.9589)  loss_classifier: 0.6019 (0.6026)  loss_box_reg: 0.9708 (0.9551)  loss_mask: 2.8513 (2.9999)  loss_objectness: 0.0517 (0.0932)  loss_rpn_box_reg: 0.2893 (0.3082)  time: 16.0266  data: 14.7184  max mem: 7784\nEpoch: [0]  [25/80]  eta: 0:14:46  lr: 0.000099  loss: 4.2710 (4.7340)  loss_classifier: 0.5921 (0.5971)  loss_box_reg: 0.9463 (0.9489)  loss_mask: 2.5201 (2.8017)  loss_objectness: 0.0462 (0.0845)  loss_rpn_box_reg: 0.2874 (0.3018)  time: 15.8783  data: 14.5742  max mem: 7784\nEpoch: [0]  [30/80]  eta: 0:13:33  lr: 0.000118  loss: 3.9566 (4.5127)  loss_classifier: 0.5787 (0.5915)  loss_box_reg: 0.9391 (0.9460)  loss_mask: 2.0876 (2.6086)  loss_objectness: 0.0383 (0.0762)  loss_rpn_box_reg: 0.2532 (0.2903)  time: 16.0771  data: 14.7662  max mem: 7928\nEpoch: [0]  [35/80]  eta: 0:12:16  lr: 0.000137  loss: 3.3815 (4.3117)  loss_classifier: 0.5664 (0.5842)  loss_box_reg: 0.9224 (0.9406)  loss_mask: 1.6760 (2.4320)  loss_objectness: 0.0366 (0.0702)  loss_rpn_box_reg: 0.2484 (0.2847)  time: 16.3287  data: 15.0125  max mem: 7928\nEpoch: [0]  [40/80]  eta: 0:10:52  lr: 0.000156  loss: 3.1774 (4.1355)  loss_classifier: 0.5504 (0.5764)  loss_box_reg: 0.9159 (0.9372)  loss_mask: 1.3829 (2.2745)  loss_objectness: 0.0323 (0.0657)  loss_rpn_box_reg: 0.2418 (0.2816)  time: 16.4570  data: 15.1372  max mem: 7928\nEpoch: [0]  [45/80]  eta: 0:09:30  lr: 0.000175  loss: 2.9281 (3.9903)  loss_classifier: 0.5301 (0.5684)  loss_box_reg: 0.9111 (0.9331)  loss_mask: 1.1838 (2.1493)  loss_objectness: 0.0289 (0.0630)  loss_rpn_box_reg: 0.2405 (0.2765)  time: 16.5518  data: 15.2310  max mem: 7928\nEpoch: [0]  [50/80]  eta: 0:08:09  lr: 0.000194  loss: 2.8205 (3.8494)  loss_classifier: 0.5083 (0.5605)  loss_box_reg: 0.8985 (0.9271)  loss_mask: 1.1260 (2.0270)  loss_objectness: 0.0299 (0.0607)  loss_rpn_box_reg: 0.2433 (0.2741)  time: 16.3749  data: 15.0592  max mem: 7928\nEpoch: [0]  [55/80]  eta: 0:06:51  lr: 0.000213  loss: 2.6241 (3.7190)  loss_classifier: 0.4939 (0.5530)  loss_box_reg: 0.8920 (0.9228)  loss_mask: 0.9539 (1.9140)  loss_objectness: 0.0299 (0.0580)  loss_rpn_box_reg: 0.2433 (0.2711)  time: 16.5990  data: 15.2767  max mem: 7940\nEpoch: [0]  [60/80]  eta: 0:05:29  lr: 0.000232  loss: 2.4344 (3.5992)  loss_classifier: 0.4829 (0.5453)  loss_box_reg: 0.8840 (0.9178)  loss_mask: 0.7939 (1.8120)  loss_objectness: 0.0299 (0.0558)  loss_rpn_box_reg: 0.2402 (0.2683)  time: 16.8247  data: 15.4844  max mem: 7940\nEpoch: [0]  [65/80]  eta: 0:04:06  lr: 0.000251  loss: 2.3267 (3.4897)  loss_classifier: 0.4672 (0.5367)  loss_box_reg: 0.8672 (0.9125)  loss_mask: 0.7206 (1.7208)  loss_objectness: 0.0333 (0.0539)  loss_rpn_box_reg: 0.2385 (0.2658)  time: 16.8011  data: 15.4610  max mem: 7940\nEpoch: [0]  [70/80]  eta: 0:02:44  lr: 0.000270  loss: 2.1880 (3.3938)  loss_classifier: 0.4443 (0.5277)  loss_box_reg: 0.8612 (0.9080)  loss_mask: 0.6319 (1.6403)  loss_objectness: 0.0337 (0.0531)  loss_rpn_box_reg: 0.2385 (0.2648)  time: 16.7902  data: 15.4506  max mem: 7940\nEpoch: [0]  [75/80]  eta: 0:01:22  lr: 0.000289  loss: 2.1375 (3.3040)  loss_classifier: 0.4155 (0.5191)  loss_box_reg: 0.8402 (0.9026)  loss_mask: 0.5785 (1.5677)  loss_objectness: 0.0320 (0.0514)  loss_rpn_box_reg: 0.2286 (0.2631)  time: 16.6048  data: 15.2694  max mem: 7940\nEpoch: [0]  [79/80]  eta: 0:00:16  lr: 0.000300  loss: 2.0756 (3.2389)  loss_classifier: 0.4048 (0.5122)  loss_box_reg: 0.8332 (0.8982)  loss_mask: 0.5689 (1.5163)  loss_objectness: 0.0320 (0.0505)  loss_rpn_box_reg: 0.2308 (0.2617)  time: 16.5790  data: 15.2573  max mem: 7940\nEpoch: [0] Total time: 0:22:00 (16.5116 s / it)\ncreating index...\nindex created!\nTest:  [ 0/50]  eta: 0:10:33  model_time: 4.5272 (4.5272)  evaluator_time: 4.7303 (4.7303)  time: 12.6752  data: 3.3853  max mem: 10054\nTest:  [49/50]  eta: 0:00:12  model_time: 4.2944 (4.3387)  evaluator_time: 4.5809 (4.6447)  time: 12.2291  data: 2.9745  max mem: 10054\nTest: Total time: 0:10:16 (12.3367 s / it)\nAveraged stats: model_time: 4.2944 (4.3387)  evaluator_time: 4.5809 (4.6447)\nAccumulating evaluation results...\nDONE (t=0.01s).\nAccumulating evaluation results...\nDONE (t=0.01s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\nIoU metric: segm\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [1:13:22<00:00, 4402.63s/it]","output_type":"stream"},{"name":"stdout","text":"That's it\n[190, 636, 378, 615, 199, 472, 598, 576, 454, 526]\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"from copy import deepcopy\ndef just_a_try():\n    idx=636\n    imgs= list(sorted(os.listdir('/kaggle/input/data-train/data_train')))\n    bk_img=Book_Image(os.path.join('/kaggle/input/data-train/data_train',imgs[idx]),with_mask=True,encode='utf-8')\n    \n    image = torch.as_tensor(np.array(bk_img.trans_image, dtype=np.uint8), dtype=torch.float32)\n    image = image.permute(2, 0, 1).div(255)\n        \n    # Wrap sample and targets into torchvision tv_tensors:\n    #print(image)\n    \n    torch.cuda.empty_cache()\n    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\n    \n    model = torch.load('/kaggle/working/bk_spine_segmentation0.pth')\n    model.to(device)\n    model.eval()\n    print('predicting')\n    with torch.no_grad():\n        output = model([image.to(device)])\n        pred = output[0]\n    \n    masks = (pred[\"masks\"] > 0.5).squeeze(1)\n    #print(pred)\n    obj_idx=33\n    mm=masks[obj_idx].cpu().numpy()\n    mm=np.array(mm,dtype=np.uint8)\n    mm[mm == 1] = 255\n    print(np.unique(mm))\n    mi=Image.fromarray(mm,mode='L')\n    mi.save('/kaggle/working/mask.jpeg',format='jpeg')\n    print(mm)\n    box=list(pred['boxes'][obj_idx].cpu().numpy())\n    print(box)\n\n    draw=ImageDraw.Draw(bk_img.image)\n    draw.rectangle(box,outline='red',width=5)\n    bk_img.image.save('/kaggle/working/toshow_image.jpeg',format='jpeg')\njust_a_try()","metadata":{"execution":{"iopub.status.busy":"2024-08-27T13:45:15.888623Z","iopub.execute_input":"2024-08-27T13:45:15.889034Z","iopub.status.idle":"2024-08-27T13:45:18.928763Z","shell.execute_reply.started":"2024-08-27T13:45:15.889004Z","shell.execute_reply":"2024-08-27T13:45:18.927773Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"predicting\n[  0 255]\n[[0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n ...\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]]\n[3188.2307, 577.6584, 3492.7954, 2976.0]\n","output_type":"stream"}]}]}